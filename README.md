# Q1

This repository contains the implementation of a **Vision Transformer (ViT)** model for image classification.


## Overview

The Vision Transformer (ViT) applies a Transformer architecture, originally designed for NLP, to image classification tasks. It divides images into patches and processes them as a sequence, leveraging self-attention mechanisms to capture global dependencies.

---

## Model Architecture

* Input: Image patches of size `32x32`
* Embedding: Linear projection of flattened patches + positional embeddings
* Transformer Encoder:

  * Multi-head self-attention
  * MLP layers
  * Layer normalization
  * Residual connections
* Classification head: Fully connected layer with softmax activation

---

## Dataset

* Dataset name: `CIFAR10`
* Number of classes: `10`
---

## Run & Check Accuracy



3. **Best accuracy tested**

   ```
   Test Accuracy: 67.35%
   ```

---

## Installation

1. Clone the repository:

   ```bash
   git clone <repo-url>
   cd <repo-directory>
   ```
2. install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

---

## Usage

Open the .ipynb file and run all cells

---

## References

* [Dosovitskiy et al., 2020: An Image is Worth 16x16 Words](https://arxiv.org/abs/2010.11929)

# Q2

## SAM2 Model Usage with Grounding DINO Text Prompts

This guide explains how to use the **pretrained SAM2 (Segment Anything Model 2)** for image segmentation with **text prompts generated by Grounding DINO**, without training the model.

---

## Usage Steps

1. **Prepare your images**

   * Organize your images in a folder for processing.

2. **Load the pretrained SAM2 model**

   * Use the model in evaluation mode for inference.

3. **Load the Grounding DINO model**

   * Use it to generate text prompts based on the content of the images.

4. **Generate text prompts**

   * Apply Grounding DINO on your images to create descriptive prompts for segmentation.

5. **Segment images using SAM2**

   * Provide the generated text prompts to SAM2 to obtain segmentation masks.

6. **Visualize or save results**

   * Save the segmentation masks or visualize them directly for analysis.

---

This workflow allows you to perform image segmentation using SAM2 guided by **Grounding DINO text prompts**, without needing to train any models.
